import os
import shutil
import random
import argparse
import cv2
import numpy as np
import re
import glob
# from glob import glob
from PIL import Image, ImageDraw
from tqdm import tqdm

##############################################################
# polygon ì‚°(/\_/\)ëª¨ì–‘ë„ ë°”ë‹¥ ì„ ê¹Œì§€ ë§Œë“¤ê¸°ê¸°
##############################################################
def get_signal_peak_points(img):
    """ë…¸ë€ìƒ‰ ì ë“¤ì˜ ì¤‘ì‹¬ ì¢Œí‘œ(Peak)ë¥¼ ì¶”ì¶œí•˜ì—¬ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    lower_yellow = np.array([10, 50, 50])
    upper_yellow = np.array([40, 255, 255])
    binary_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

    contours, _ = cv2.findContours(
        binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
    )

    peak_points = []
    for cnt in contours:
        M = cv2.moments(cnt)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            peak_points.append([cx, cy])

    if peak_points:
        peak_points = sorted(peak_points, key=lambda x: x[0])

    return binary_mask, peak_points

def create_waveform_polygon(
    peak_points,
    rx,
    ry,
    img_w,
    img_h,
    peak_h=50,
    valley_h=10
):
    pts = np.array(peak_points, dtype=np.float32)
    pts[:, 0] += rx
    pts[:, 1] += ry

    upper_line = []

    for i in range(len(pts)):
        x, y = pts[i]

        # ğŸ”º Peak
        upper_line.append([x, max(0, y - peak_h)])

        # ğŸ”» Valley
        if i < len(pts) - 1:
            nx, ny = pts[i + 1]
            mid_x = (x + nx) / 2
            mid_y = max(0, (y + ny) / 2 - valley_h)
            upper_line.append([mid_x, mid_y])

    # ğŸ”¥ í•µì‹¬: ì œì¼ ì•„ë˜ ë‘ ì ì„ ì—°ê²°
    left_x, left_y = pts[0]
    right_x, right_y = pts[-1]

    bottom_y = max(left_y, right_y)

    bottom_left = [left_x, bottom_y]
    bottom_right = [right_x, bottom_y]

    # í´ë¦¬ê³¤ êµ¬ì„± (ì‹œê³„ë°©í–¥)
    full_polygon = (
        [bottom_left] +
        upper_line +
        [bottom_right]
    )

    poly = np.array(full_polygon, dtype=np.float32)

    # ì´ë¯¸ì§€ ê²½ê³„ í´ë¦¬í•‘
    poly[:, 0] = np.clip(poly[:, 0], 0, img_w - 1)
    poly[:, 1] = np.clip(poly[:, 1], 0, img_h - 1)

    return poly

def synthesize_advanced_mountain_shape(
    signal_path,
    bg_folder,
    output_root,
    num_gen=10,
    mask_type='polygon'
):
    signal_name = os.path.splitext(os.path.basename(signal_path))[0]
    class_id = extract_class_id(signal_name)

    save_dirs = {
        "images": os.path.join(output_root, "images"),
        "labels": os.path.join(output_root, "labels"),
        "debug": os.path.join(output_root, "debug"),
    }
    for p in save_dirs.values():
        os.makedirs(p, exist_ok=True)

    bg_list = [
        f for f in glob.glob(os.path.join(bg_folder, "*.*"))
        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))
    ]

    if not bg_list:
        print("âŒ ë°°ê²½ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    pattern_img = cv2.imread(signal_path)
    binary_mask, peak_points = get_signal_peak_points(pattern_img)

    if not peak_points:
        print(f"âŒ '{signal_name}'ì—ì„œ peakë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # âœ… ì˜¬ë°”ë¥¸ boundingRect ê³„ì‚°
    ys, xs = np.where(binary_mask > 0)
    x, y, w, h = cv2.boundingRect(
        np.column_stack((xs, ys)).astype(np.int32)
    )

    crop_img = pattern_img[y:y+h, x:x+w]
    crop_binary = binary_mask[y:y+h, x:x+w]
    adjusted_peaks = [[p[0] - x, p[1] - y] for p in peak_points]

    print(f"ğŸš€ '{signal_name}' (Class {class_id}) í•©ì„± ì‹œì‘")

    for i in range(num_gen):
        bg = cv2.imread(random.choice(bg_list))
        if bg is None:
            continue

        debug = bg.copy()
        bg_h, bg_w = bg.shape[:2]

        if bg_w <= w or bg_h <= h:
            continue

        rx = random.randint(0, bg_w - w)
        ry = random.randint(0, bg_h - h)

        roi = bg[ry:ry+h, rx:rx+w]
        bg_part = cv2.bitwise_and(roi, roi, mask=cv2.bitwise_not(crop_binary))
        fg_part = cv2.bitwise_and(crop_img, crop_img, mask=crop_binary)
        bg[ry:ry+h, rx:rx+w] = cv2.add(bg_part, fg_part)

        # í´ë¦¬ê³¤ ìƒì„±
        # ê³ ì •ê°’ ëŒ€ì‹  ì•½ê°„ì˜ ëœë¤ ë²”ìœ„ë¥¼ ì£¼ë©´ ì¦ê°•(Augmentation) íš¨ê³¼ê°€ ë‚©ë‹ˆë‹¤.
        rand_peak = random.randint(45, 65)    # ì‚° ë†’ì´ì— ë³€í™”
        rand_valley = random.randint(10, 20)  # ê³¨ì§œê¸° ê¹Šì´ì— ë³€í™”

        final_poly = create_waveform_polygon(
            adjusted_peaks,
            rx,
            ry,
            img_w=bg_w,
            img_h=bg_h,
            peak_h=rand_peak,
            valley_h=rand_valley
        )

        poly_draw = final_poly.astype(np.int32).reshape((-1, 1, 2))

        # ğŸ”´ ë””ë²„ê·¸ ì‹œê°í™”
        cv2.polylines(
            debug,
            [poly_draw],
            True,
            (0, 0, 255),
            3,
            cv2.LINE_AA
        )

        for p in poly_draw:
            cv2.circle(debug, tuple(p[0]), 3, (255, 0, 0), -1)

        cv2.putText(
            debug,
            f"ID:{class_id}",
            (poly_draw[0][0][0], max(0, poly_draw[0][0][1] - 10)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 0, 255),
            2
        )

        # YOLO polygon label
        poly_str = " ".join(
            [f"{p[0]/bg_w:.6f} {p[1]/bg_h:.6f}" for p in final_poly]
        )
        label_line = f"{class_id} {poly_str}"

        name = f"{signal_name}_{i:04d}"
        cv2.imwrite(os.path.join(save_dirs["images"], f"{name}.png"), bg)
        cv2.imwrite(os.path.join(save_dirs["debug"], f"{name}_debug.png"), debug)

        with open(os.path.join(save_dirs["labels"], f"{name}.txt"), "w") as f:
            f.write(label_line)

    print(f"âœ… ì™„ë£Œ: {output_root}")
####################################################################################

def get_signal_skeleton_mask_line(img, thickness=2):
    """ì ë“¤ì˜ ì¤‘ì‹¬ì„ ì°¾ì•„ ìˆœì„œëŒ€ë¡œ ì„ ìœ¼ë¡œ ì—°ê²°í•œ ê³¨ê²© ë§ˆìŠ¤í¬ ìƒì„±"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_yellow = np.array([10, 50, 50]) 
    upper_yellow = np.array([40, 255, 255])
    binary_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

    skeleton = np.zeros_like(binary_mask)
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return binary_mask, binary_mask

    # 1. ê° ì (Contour)ì˜ ì¤‘ì‹¬ì (Center) ì¶”ì¶œ
    centers = []
    for cnt in contours:
        M = cv2.moments(cnt)
        if M["m00"] != 0:
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            centers.append([cX, cY])
        else:
            # ë©´ì ì´ ë„ˆë¬´ ì‘ì€ ê²½ìš° ëŒ€í‘œ ì  í•˜ë‚˜ ì¶”ì¶œ
            centers.append(cnt[0][0].tolist())

    # 2. ì ë“¤ì„ xì¶• ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì„ ì„ ì‡ê¸° ìœ„í•¨)
    centers = sorted(centers, key=lambda x: x[0])
    pts = np.array(centers, np.int32)
    pts = pts.reshape((-1, 1, 2))

    # 3. ì ë“¤ì„ ì„ ìœ¼ë¡œ ì—°ê²° (Skeletal Line)
    # thicknessë¥¼ ì¡°ì ˆí•˜ì—¬ ì„ ì˜ êµµê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    cv2.polylines(skeleton, [pts], isClosed=False, color=255, thickness=thickness)

    return binary_mask, skeleton

def get_signal_skeleton_mask_polygon(img):
    """ì ë“¤ì„ ì—°ê²°í•˜ì—¬ ì‹œê·¸ë„ì˜ 'ëª¨ì–‘'ì„ ê°€ì§„ ë§ˆìŠ¤í¬ ìƒì„±"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_yellow = np.array([10, 50, 50]) 
    upper_yellow = np.array([40, 255, 255])
    binary_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

    skeleton = np.zeros_like(binary_mask)
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return binary_mask, binary_mask

    all_points = np.vstack(contours)
    hull = cv2.convexHull(all_points)
    cv2.drawContours(skeleton, [hull], -1, 255, thickness=-1) 

    return binary_mask, skeleton

def extract_class_id(filename):
    """íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ì°¾ì•„ class IDë¡œ ë°˜í™˜ (ìˆ«ìê°€ ì—†ìœ¼ë©´ 0)"""
    numbers = re.findall(r'\d+', filename)
    if numbers:
        # ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì—¬ class id ê²°ì • (signal_1 -> class 0, signal_2 -> class 1)
        if (int(numbers[-1]) - 1) < 0:
            return 0
        else:
            return int(numbers[-1]) - 1 # ê°€ì¥ ë§ˆì§€ë§‰ì— ë“±ì¥í•˜ëŠ” ìˆ«ì ë°˜í™˜
    else:
        print(f"ê²½ê³ : íŒŒì¼ëª…ì—ì„œ ìˆ«ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í´ë˜ìŠ¤ 0ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {filename}")        
        return 0

def synthesize_advanced(signal_path, bg_folder, output_root, num_gen=10, mask_type='polygon'):
    # 1. íŒŒì¼ ì´ë¦„ ì„¤ì • ë° class ID ì¶”ì¶œ
    signal_basename = os.path.basename(signal_path)
    signal_name = os.path.splitext(signal_basename)[0]
    class_id = extract_class_id(signal_name)
    
    save_dirs = {
        "images": os.path.join(output_root, "images"),
        "labels": os.path.join(output_root, "labels"),
        "debug": os.path.join(output_root, "debug")
    }
    for p in save_dirs.values():
        os.makedirs(p, exist_ok=True)

    bg_list = glob.glob(os.path.join(bg_folder, "*.*"))
    bg_list = [f for f in bg_list if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
    
    if not bg_list:
        print("âŒ ë°°ê²½ í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    pattern_img = cv2.imread(signal_path)
    if mask_type == 'line':
        binary_mask, skeleton_mask = get_signal_skeleton_mask_line(pattern_img)
    elif mask_type == 'polygon':
        binary_mask, skeleton_mask = get_signal_skeleton_mask_polygon(pattern_img)
    else:
        print("âŒ ì˜¬ë°”ë¥¸ ë§ˆìŠ¤í¬ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return

    coords = cv2.findNonZero(binary_mask)
    if coords is None:
        print("âŒ ì‹œê·¸ë„ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    x, y, w, h = cv2.boundingRect(coords)
    crop_img = pattern_img[y:y+h, x:x+w]
    crop_binary = binary_mask[y:y+h, x:x+w]
    crop_skeleton = skeleton_mask[y:y+h, x:x+w]

    print(f"ğŸš€ '{signal_name}' (Class ID: {class_id}) íŒ¨í„´ìœ¼ë¡œ {num_gen}ê°œ ìƒì„± ì‹œì‘")

    for i in range(num_gen):
        bg_path = random.choice(bg_list)
        bg_img_origin = cv2.imread(bg_path)
        
        bg = bg_img_origin.copy()
        debug = bg_img_origin.copy()
        bg_h, bg_w, _ = bg.shape

        if bg_w <= w or bg_h <= h:
            continue

        rx = random.randint(0, bg_w - w)
        ry = random.randint(0, bg_h - h)

        # ì´ë¯¸ì§€ í•©ì„±
        roi = bg[ry:ry+h, rx:rx+w]
        bg_part = cv2.bitwise_and(roi, roi, mask=cv2.bitwise_not(crop_binary))
        fg_part = cv2.bitwise_and(crop_img, crop_img, mask=crop_binary)
        bg[ry:ry+h, rx:rx+w] = cv2.add(bg_part, fg_part)

        # ë¼ë²¨ ìƒì„±
        contours, _ = cv2.findContours(crop_skeleton, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        yolo_labels = []
        for cnt in contours:
            abs_cnt = cnt.copy()
            abs_cnt[:, 0, 0] += rx
            abs_cnt[:, 0, 1] += ry
            
            # ë””ë²„ê¹… ì´ë¯¸ì§€ì— class ID í…ìŠ¤íŠ¸ ì¶”ê°€
            cv2.drawContours(debug, [abs_cnt], -1, (0, 255, 0), 2)
            cv2.putText(debug, f"ID: {class_id}", (rx, ry-10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            polygon = []
            for p in abs_cnt:
                polygon.append(f"{p[0][0]/bg_w:.6f} {p[0][1]/bg_h:.6f}")
            # ì²« ë²ˆì§¸ ì¸ìì— ì¶”ì¶œí•œ class_id ì ìš©
            yolo_labels.append(f"{class_id} {' '.join(polygon)}")

        save_name = f"{signal_name}_{i:04d}"
        cv2.imwrite(os.path.join(save_dirs["images"], f"{save_name}.png"), bg)
        cv2.imwrite(os.path.join(save_dirs["debug"], f"{save_name}_debug.png"), debug)
        with open(os.path.join(save_dirs["labels"], f"{save_name}.txt"), 'w') as f:
            f.write('\n'.join(yolo_labels))

    print(f"âœ… ì™„ë£Œ: {output_root}")

def delete_files_with_suffix(directory, suffix):
    """
    íŠ¹ì • ì ‘ë¯¸ì‚¬ë¥¼ í¬í•¨í•˜ëŠ” íŒŒì¼ ì‚­ì œ
    
    Args:
        directory: ëŒ€ìƒ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        suffix: ì‚­ì œí•  íŒŒì¼ì˜ ì ‘ë¯¸ì‚¬
    """
    # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  íŒŒì¼ì„ ìˆœíšŒ
    for filename in tqdm(os.listdir(directory)):
        # íŒŒì¼ëª…ì´ ì ‘ë¯¸ì‚¬ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
        if filename.endswith(suffix):
            file_path = os.path.join(directory, filename)
            try:
                # íŒŒì¼ ì‚­ì œ
                os.remove(file_path)
                print(f"Deleted: {file_path}")
            except Exception as e:
                print(f"Error deleting {file_path}: {e}")

def create_directory_structure(base_dir):
    """
    í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    
    ê¸°ë³¸ êµ¬ì¡°:
        base_dir/train
        base_dir/val
        base_dir/test
    
    (YOLO ì „ìš© êµ¬ì¡°ëŠ” `split_dataset`ì—ì„œ ë³„ë„ë¡œ ìƒì„±)
    
    Args:
        base_dir: ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    os.makedirs(base_dir, exist_ok=True)
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(base_dir, split), exist_ok=True)
    
    print(f"ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {base_dir}")

def split_dataset(images_dir, labels_dir, masks_dir, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, random_seed=42):
    """
    ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í•  (YOLO ë°ì´í„°ì…‹ êµ¬ì¡°ë¡œ ì €ì¥)
    
    Args:
        images_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        labels_dir: ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œ (YOLO í˜•ì‹ txt íŒŒì¼)
        masks_dir: ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì„ íƒì )
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: ./datasets)
            - images/train, images/val, images/test
            - labels/train, labels/val, labels/test
            - (ì„ íƒ) masks/train, masks/val, masks/test
        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨
        val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        test_ratio: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
        random_seed: ëœë¤ ì‹œë“œ
    """
    # YOLO í˜•ì‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(output_dir, 'images', split), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'labels', split), exist_ok=True)
        if masks_dir:
            os.makedirs(os.path.join(output_dir, 'masks', split), exist_ok=True)
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = [f for f in os.listdir(images_dir) if any(f.lower().endswith(ext) for ext in image_extensions)]
    
    # ëœë¤ ì‹œë“œ ì„¤ì •
    random.seed(random_seed)
    random.shuffle(image_files)
    
    # ë¶„í•  ì¸ë±ìŠ¤ ê³„ì‚°
    total = len(image_files)
    train_end = int(total * train_ratio)
    val_end = train_end + int(total * val_ratio)
    
    # ë¶„í•  ë°ì´í„° ì¤€ë¹„
    splits = {
        'train': image_files[:train_end],
        'val': image_files[train_end:val_end],
        'test': image_files[val_end:]
    }
    
    # ê° ë¶„í• ì— ëŒ€í•´ íŒŒì¼ ë³µì‚¬ (YOLO êµ¬ì¡°: images/â€¦, labels/â€¦, masks/â€¦)
    for split, files in splits.items():
        print(f"{split} ë°ì´í„° ë³µì‚¬ ì¤‘: {len(files)} íŒŒì¼")
        for file in tqdm(files):
            # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬
            src_image = os.path.join(images_dir, file)
            dst_image = os.path.join(output_dir, 'images', split, file)
            shutil.copy2(src_image, dst_image)
            
            # ë¼ë²¨ íŒŒì¼ ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
            base_name = os.path.splitext(file)[0]
            src_label = os.path.join(labels_dir, f"{base_name}.txt")
            dst_label = os.path.join(output_dir, 'labels', split, f"{base_name}.txt")
            if os.path.exists(src_label):
                shutil.copy2(src_label, dst_label)
            
            # ë§ˆìŠ¤í¬ íŒŒì¼ ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
            if masks_dir:
                src_mask = os.path.join(masks_dir, f"{base_name}_mask.png")
                dst_mask = os.path.join(output_dir, 'masks', split, f"{base_name}_mask.png")
                if os.path.exists(src_mask):
                    shutil.copy2(src_mask, dst_mask)
    
    print("ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ!")
    print(f"í•™ìŠµ: {len(splits['train'])} íŒŒì¼")
    print(f"ê²€ì¦: {len(splits['val'])} íŒŒì¼")
    print(f"í…ŒìŠ¤íŠ¸: {len(splits['test'])} íŒŒì¼")

def split_sliced_dataset(image_dir, label_dir, output_base_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, random_seed=42):
    """
    image_dir: ìŠ¬ë¼ì´ì‹±ëœ ì›ë³¸ ì´ë¯¸ì§€ í´ë”
    label_dir: ìŠ¬ë¼ì´ì‹±ëœ ì›ë³¸ ë¼ë²¨ í´ë”
    output_base_dir: ìµœì¢… ë°ì´í„°ì…‹ ë£¨íŠ¸
            - images/train, images/val, images/test
            - labels/train, labels/val, labels/test
    """
    # 1. ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    all_images = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]
    
    # 2. ì›ë³¸ ì´ë¦„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™” (íŒŒì¼ëª… ê·œì¹™: {name}_{x}_{y}.png)
    original_groups = {}
    for f in all_images:
        parts = f.rsplit('_', 2)
        orig_name = parts[0]
        if orig_name not in original_groups:
            original_groups[orig_name] = []
        original_groups[orig_name].append(f)

    # 3. ì›ë³¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì…”í”Œ (ëœë¤ì„± ë¶€ì—¬)
    orig_names = list(original_groups.keys())
    random.seed(random_seed)
    random.shuffle(orig_names)

    # 4. ë¶„í•  ì§€ì  ê³„ì‚°
    total_count = len(orig_names)
    train_end = int(total_count * train_ratio)
    val_end = train_end + int(total_count * val_ratio)

    split_map = {
        'train': orig_names[:train_end],
        'val': orig_names[train_end:val_end],
        'test': orig_names[val_end:]
    }

    print(f"--- [ë°ì´í„° ë¶„í•  ì‹œì‘: ì‚¬ìš©ì ì§€ì • êµ¬ì¡°] ---")
    print(f"ì „ì²´ ì›ë³¸ ì´ë¯¸ì§€ ìˆ˜: {total_count}")

    # 5. íŒŒì¼ ë³µì‚¬ ë° í´ë” ì •ë¦¬
    for split_name, orig_list in split_map.items():
        # ì‚¬ìš©ì ìš”ì²­ êµ¬ì¡°: output_base_dir/images/train... ë° output_base_dir/labels/train...
        target_img_dir = os.path.join(output_base_dir, 'images', split_name)
        target_lbl_dir = os.path.join(output_base_dir, 'labels', split_name)
        
        os.makedirs(target_img_dir, exist_ok=True)
        os.makedirs(target_lbl_dir, exist_ok=True)

        for orig in tqdm(orig_list, desc=f"ì •ë¦¬ ì¤‘: {split_name}"):
            for img_file in original_groups[orig]:
                # 1. ì´ë¯¸ì§€ ë³µì‚¬ (src -> images/{train,val,test})
                shutil.copy(
                    os.path.join(image_dir, img_file), 
                    os.path.join(target_img_dir, img_file)
                )
                
                # 2. ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ ë³µì‚¬ (src -> labels/{train,val,test})
                lbl_file = os.path.splitext(img_file)[0] + '.txt'
                src_lbl_path = os.path.join(label_dir, lbl_file)
                
                if os.path.exists(src_lbl_path):
                    shutil.copy(src_lbl_path, os.path.join(target_lbl_dir, lbl_file))

    print(f"\nâœ… ë¶„í•  ì™„ë£Œ!")
    print(f"ğŸ“‚ êµ¬ì¡° í™•ì¸:")
    print(f"   - {output_base_dir}/images/{{train, val, test}}")
    print(f"   - {output_base_dir}/labels/{{train, val, test}}")

def create_mask_from_bbox(image_path, label_path, output_path, dilation_size=5):
    """
    ë°”ìš´ë”© ë°•ìŠ¤ë¡œë¶€í„° ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ìƒì„±
    
    Args:
        image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        label_path: ë¼ë²¨ íŒŒì¼ ê²½ë¡œ (YOLO í˜•ì‹ txt)
        output_path: ì¶œë ¥ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ê²½ë¡œ
        dilation_size: ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ íŒ½ì°½ì‹œí‚¬ í¬ê¸° (í”½ì…€)
    """
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path)
    width, height = image.size
    
    # ë§ˆìŠ¤í¬ ìƒì„± (ê²€ì€ìƒ‰ ë°°ê²½)
    mask = Image.new('L', (width, height), 0)
    draw = ImageDraw.Draw(mask)
    
    # ë¼ë²¨ íŒŒì¼ ì½ê¸°
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            for line in f:
                values = line.strip().split()
                if len(values) == 5:
                    # YOLO í˜•ì‹: class_id x_center y_center width height
                    class_id = int(values[0])
                    x_center = float(values[1]) * width
                    y_center = float(values[2]) * height
                    box_width = float(values[3]) * width
                    box_height = float(values[4]) * height
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚°
                    x1 = max(0, int(x_center - box_width / 2))
                    y1 = max(0, int(y_center - box_height / 2))
                    x2 = min(width - 1, int(x_center + box_width / 2))
                    y2 = min(height - 1, int(y_center + box_height / 2))
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ë‚´ë¶€ë¥¼ í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
                    draw.rectangle([x1, y1, x2, y2], fill=255)
    
    # íŒ½ì°½ ì ìš© (ì˜¤ë¸Œì íŠ¸ ì‚¬ì´ì˜ ë°°ê²½ì„ ë” ì˜ ë¶„ë¦¬í•˜ê¸° ìœ„í•¨)
    if dilation_size > 0:
        # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        mask_np = np.array(mask)
        kernel = np.ones((dilation_size, dilation_size), np.uint8)
        dilated_mask = cv2.dilate(mask_np, kernel, iterations=1)
        
        # ë‹¤ì‹œ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        mask = Image.fromarray(dilated_mask)
    
    # ë§ˆìŠ¤í¬ ì €ì¥
    mask.save(output_path)
    return mask

def create_masks_for_dataset(dataset_dir, output_dir=None, dilation_size=5):
    """
    ë°ì´í„°ì…‹ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ë§ˆìŠ¤í¬ ìƒì„±
    
    Args:
        dataset_dir: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ í¬í•¨)
        output_dir: ë§ˆìŠ¤í¬ ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ dataset_dirê³¼ ë™ì¼)
        dilation_size: ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ íŒ½ì°½ì‹œí‚¬ í¬ê¸° (í”½ì…€)
    """
    if output_dir is None:
        output_dir = dataset_dir
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = [f for f in os.listdir(dataset_dir) 
                   if any(f.lower().endswith(ext) for ext in image_extensions) 
                   and '_masked' not in f]
    
    print(f"ë§ˆìŠ¤í¬ ìƒì„± ì¤‘: {len(image_files)} íŒŒì¼")
    for file in tqdm(image_files):
        # íŒŒì¼ ê²½ë¡œ
        image_path = os.path.join(dataset_dir, file)
        base_name = os.path.splitext(file)[0]
        label_path = os.path.join(dataset_dir, f"{base_name}.txt")
        mask_output_path = os.path.join(output_dir, f"{base_name}_masked.png")
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        create_mask_from_bbox(image_path, label_path, mask_output_path, dilation_size)
    
    print(f"ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ: {len(image_files)} íŒŒì¼")

def augment_dataset(dataset_dir, num_augmentations=5, random_seed=42):
    """
    ë°ì´í„°ì…‹ ì¦ê°•: íšŒì „, ìƒ‰ìƒ ë³€í™”, ë…¸ì´ì¦ˆ ì¶”ê°€ ë“±
    
    Args:
        dataset_dir: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        num_augmentations: ê° ì´ë¯¸ì§€ë‹¹ ìƒì„±í•  ì¦ê°• ì´ë¯¸ì§€ ìˆ˜
        random_seed: ëœë¤ ì‹œë“œ
    """
    random.seed(random_seed)
    np.random.seed(random_seed)
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = [f for f in os.listdir(dataset_dir) 
                   if any(f.lower().endswith(ext) for ext in image_extensions) 
                   and '_mask' not in f 
                   and '_aug' not in f]
    
    print(f"ë°ì´í„° ì¦ê°• ì¤‘: {len(image_files)} íŒŒì¼ x {num_augmentations} ì¦ê°• = {len(image_files) * num_augmentations} íŒŒì¼")
    
    for file in tqdm(image_files):
        # íŒŒì¼ ê²½ë¡œ
        image_path = os.path.join(dataset_dir, file)
        base_name = os.path.splitext(file)[0]
        ext = os.path.splitext(file)[1]
        label_path = os.path.join(dataset_dir, f"{base_name}.txt")
        mask_path = os.path.join(dataset_dir, f"{base_name}_mask.png")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        height, width = image.shape[:2]
        
        # ë¼ë²¨ ë¡œë“œ
        labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    labels.append(line.strip())
        
        # ë§ˆìŠ¤í¬ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        mask = None
        if os.path.exists(mask_path):
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        # ê° ì¦ê°•ì— ëŒ€í•´
        for i in range(num_augmentations):
            # ëœë¤ ì¦ê°• ì ìš©
            aug_image = image.copy()
            aug_mask = mask.copy() if mask is not None else None
            
            # 1. íšŒì „ (ì‘ì€ ê°ë„)
            angle = random.uniform(-15, 15)
            M = cv2.getRotationMatrix2D((width/2, height/2), angle, 1)
            aug_image = cv2.warpAffine(aug_image, M, (width, height))
            if aug_mask is not None:
                aug_mask = cv2.warpAffine(aug_mask, M, (width, height))
            
            # 2. ë°ê¸° ì¡°ì •
            brightness = random.uniform(0.8, 1.2)
            aug_image = cv2.convertScaleAbs(aug_image, alpha=brightness, beta=0)
            
            # 3. ëŒ€ë¹„ ì¡°ì •
            contrast = random.uniform(0.8, 1.2)
            aug_image = cv2.convertScaleAbs(aug_image, alpha=contrast, beta=0)
            
            # 4. ë…¸ì´ì¦ˆ ì¶”ê°€
            if random.random() < 0.5:
                noise = np.random.normal(0, 5, aug_image.shape).astype(np.uint8)
                aug_image = cv2.add(aug_image, noise)
            
            # 5. ì¢Œìš° ë°˜ì „
            if random.random() < 0.5:
                aug_image = cv2.flip(aug_image, 1)
                if aug_mask is not None:
                    aug_mask = cv2.flip(aug_mask, 1)
                
                # ë¼ë²¨ë„ ë°˜ì „í•´ì•¼ í•¨
                for j in range(len(labels)):
                    parts = labels[j].split()
                    if len(parts) == 5:
                        class_id, x_center, y_center, w, h = parts
                        # x ì¢Œí‘œ ë°˜ì „
                        x_center = str(1.0 - float(x_center))
                        labels[j] = f"{class_id} {x_center} {y_center} {w} {h}"
            
            # ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥
            aug_image_path = os.path.join(dataset_dir, f"{base_name}_aug{i+1}{ext}")
            cv2.imwrite(aug_image_path, aug_image)
            
            # ì¦ê°•ëœ ë§ˆìŠ¤í¬ ì €ì¥ (ìˆëŠ” ê²½ìš°)
            if aug_mask is not None:
                aug_mask_path = os.path.join(dataset_dir, f"{base_name}_aug{i+1}_mask.png")
                cv2.imwrite(aug_mask_path, aug_mask)
            
            # ì¦ê°•ëœ ë¼ë²¨ ì €ì¥
            if labels:
                aug_label_path = os.path.join(dataset_dir, f"{base_name}_aug{i+1}.txt")
                with open(aug_label_path, 'w') as f:
                    for label in labels:
                        f.write(f"{label}\n")
    
    print("ë°ì´í„° ì¦ê°• ì™„ë£Œ!")

def preview_dataset(dataset_dir, num_samples=5, random_seed=42):
    """
    ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸° (ì´ë¯¸ì§€, ë°”ìš´ë”© ë°•ìŠ¤, ë§ˆìŠ¤í¬ ì‹œê°í™”)
    
    Args:
        dataset_dir: ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        num_samples: ë¯¸ë¦¬ë³¼ ìƒ˜í”Œ ìˆ˜
        random_seed: ëœë¤ ì‹œë“œ
    """
    import matplotlib.pyplot as plt
    
    random.seed(random_seed)
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
    image_files = [f for f in os.listdir(dataset_dir) 
                   if any(f.lower().endswith(ext) for ext in image_extensions) 
                   and '_mask' not in f]
    
    # ëœë¤ ìƒ˜í”Œë§
    if len(image_files) > num_samples:
        image_files = random.sample(image_files, num_samples)
    
    for file in image_files:
        # íŒŒì¼ ê²½ë¡œ
        image_path = os.path.join(dataset_dir, file)
        base_name = os.path.splitext(file)[0]
        label_path = os.path.join(dataset_dir, f"{base_name}.txt")
        mask_path = os.path.join(dataset_dir, f"{base_name}_mask.png")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        height, width = image.shape[:2]
        
        # ë§ˆìŠ¤í¬ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        mask = None
        if os.path.exists(mask_path):
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        # ì„œë¸Œí”Œë¡¯ ì„¤ì •
        fig, axes = plt.subplots(1, 3 if mask is not None else 2, figsize=(15, 5))
        
        # ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        axes[0].imshow(image)
        axes[0].set_title(f"ì›ë³¸ ì´ë¯¸ì§€: {file}")
        axes[0].axis('off')
        
        # ë°”ìš´ë”© ë°•ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ í‘œì‹œ
        axes[1].imshow(image)
        axes[1].set_title("ë°”ìš´ë”© ë°•ìŠ¤")
        axes[1].axis('off')
        
        # ë¼ë²¨ íŒŒì¼ ì½ê¸° ë° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    values = line.strip().split()
                    if len(values) == 5:
                        # YOLO í˜•ì‹: class_id x_center y_center width height
                        class_id = int(values[0])
                        x_center = float(values[1]) * width
                        y_center = float(values[2]) * height
                        box_width = float(values[3]) * width
                        box_height = float(values[4]) * height
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚°
                        x1 = max(0, int(x_center - box_width / 2))
                        y1 = max(0, int(y_center - box_height / 2))
                        x2 = min(width - 1, int(x_center + box_width / 2))
                        y2 = min(height - 1, int(y_center + box_height / 2))
                        
                        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ì„¤ì •
                        color = (1, 0, 0) if class_id == 0 else (0, 1, 0)  # í´ë˜ìŠ¤ 0ì€ ë¹¨ê°„ìƒ‰, í´ë˜ìŠ¤ 1ì€ ë…¹ìƒ‰
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, 
                                          edgecolor=color, facecolor='none', linewidth=2)
                        axes[1].add_patch(rect)
                        
                        # í´ë˜ìŠ¤ ë ˆì´ë¸” í‘œì‹œ
                        axes[1].text(x1, y1 - 5, f"Class {class_id}", 
                                  color='white', fontsize=8, 
                                  bbox=dict(facecolor=color, alpha=0.7))
        
        # ë§ˆìŠ¤í¬ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
        if mask is not None:
            axes[2].imshow(mask, cmap='gray')
            axes[2].set_title("ë§ˆìŠ¤í¬")
            axes[2].axis('off')
        
        plt.tight_layout()
        plt.show()

def create_synthetic_drone_images(drone_model_path, background_dir, output_dir, num_images=100):
    """ë“œë¡  ëª¨ë¸ì„ ë‹¤ì–‘í•œ ë°°ê²½ì— í•©ì„±í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±"""
    
    # ë“œë¡  ì‹œê·¸ë„ íŒŒì¼ëª…ì—ì„œ í´ë˜ìŠ¤ ID ì¶”ì¶œ ë° íŒŒì¼ëª… ê¸°ë°˜ ì´ë¦„ ìƒì„±
    # ì˜ˆ: signal_1.png -> í´ë˜ìŠ¤ 0, signal_2.png -> í´ë˜ìŠ¤ 1
    drone_filename = os.path.basename(drone_model_path)
    # í™•ì¥ì ì œê±°í•˜ì—¬ ê¸°ë³¸ íŒŒì¼ëª… ì¶”ì¶œ
    drone_base_name = os.path.splitext(drone_filename)[0]
    
    # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ
    numbers = re.findall(r'\d+', drone_filename)
    if numbers:
        # ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ID ê²°ì • (signal_1 -> í´ë˜ìŠ¤ 0, signal_2 -> í´ë˜ìŠ¤ 1)
        class_id = int(numbers[-1]) - 1
        if class_id < 0:
            class_id = 0
    else:
        # ìˆ«ìê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 0 ì‚¬ìš©
        class_id = 0
        print(f"ê²½ê³ : íŒŒì¼ëª…ì—ì„œ ìˆ«ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í´ë˜ìŠ¤ 0ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {drone_filename}")
    
    print(f"ë“œë¡  ì‹œê·¸ë„: {drone_filename} -> í´ë˜ìŠ¤ ID: {class_id}, ê¸°ë³¸ íŒŒì¼ëª…: {drone_base_name}")
    
    # ë“œë¡  ëª¨ë¸ ì´ë¯¸ì§€ ë¡œë“œ (ì•ŒíŒŒ ì±„ë„ í¬í•¨)
    drone = cv2.imread(drone_model_path, cv2.IMREAD_UNCHANGED)
    
    # ë“œë¡  ì´ë¯¸ì§€ ë””ë²„ê¹…
    if drone is None:
        print(f"ì˜¤ë¥˜: ë“œë¡  ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {drone_model_path}")
        return
    
    print(f"ë“œë¡  ì´ë¯¸ì§€ ì •ë³´: í¬ê¸°={drone.shape}, íƒ€ì…={drone.dtype}")
    
    # ë“œë¡  ì´ë¯¸ì§€ì— ì•ŒíŒŒ ì±„ë„ì´ ì—†ìœ¼ë©´ ì¶”ê°€
    if len(drone.shape) == 2:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
        drone = cv2.cvtColor(drone, cv2.COLOR_GRAY2BGRA)
        drone[:, :, 3] = 255  # ì™„ì „ ë¶ˆíˆ¬ëª… ì„¤ì •
    elif drone.shape[2] == 3:  # BGR ì´ë¯¸ì§€, ì•ŒíŒŒ ì±„ë„ ì—†ìŒ
        b, g, r = cv2.split(drone)
        alpha = np.ones(b.shape, dtype=b.dtype) * 255
        drone = cv2.merge((b, g, r, alpha))
    
    # ë°°ê²½ ì´ë¯¸ì§€ ëª©ë¡
    backgrounds = [os.path.join(background_dir, f) for f in os.listdir(background_dir)
                  if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    
    if not backgrounds:
        print(f"ì˜¤ë¥˜: ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {background_dir}")
        return
    
    os.makedirs(output_dir, exist_ok=True)
    
    for i in range(num_images):
        # ëœë¤ ë°°ê²½ ì„ íƒ
        bg_path = random.choice(backgrounds)
        background = cv2.imread(bg_path)
        
        if background is None:
            print(f"ì˜¤ë¥˜: ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bg_path}")
            continue
        
        # ë°°ê²½ í¬ê¸° ì¡°ì •
        bg_h, bg_w = background.shape[:2]
        print(f"ë°°ê²½ í¬ê¸°: {bg_w}x{bg_h}")
        
        # ë“œë¡  í¬ê¸° ë° ìœ„ì¹˜ ëœë¤í™”
        # ì›ë³¸ ë“œë¡  í¬ê¸°
        drone_orig_h, drone_orig_w = drone.shape[:2]
        print(f"ë“œë¡  ì›ë³¸ í¬ê¸°: {drone_orig_w}x{drone_orig_h}")
        
        # ë“œë¡ ì´ ë°°ê²½ë³´ë‹¤ í¬ë©´ ë°°ê²½ì— ë§ê²Œ í¬ê¸° ì¡°ì • (ì´ ê²½ìš°ë§Œ í¬ê¸° ì¡°ì •)
        if drone_orig_w > bg_w or drone_orig_h > bg_h:
            max_width = int(bg_w)  # ë°°ê²½ì˜ 90%ë¡œ ì œí•œ
            max_height = int(bg_h)  # ë°°ê²½ì˜ 90%ë¡œ ì œí•œ
            
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©° í¬ê¸° ì¡°ì •
            width_ratio = max_width / drone_orig_w
            height_ratio = max_height / drone_orig_h
            scale_factor = min(width_ratio, height_ratio)
            
            print(f"ë“œë¡  ì´ë¯¸ì§€ê°€ ë°°ê²½ë³´ë‹¤ í½ë‹ˆë‹¤. ìŠ¤ì¼€ì¼ íŒ©í„° {scale_factor}ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
            scale = scale_factor
        else:
            # ì›ë³¸ í¬ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            scale = 1.0  # ì›ë³¸ í¬ê¸° ìœ ì§€
            
        print(f"ì ìš©ëœ ìŠ¤ì¼€ì¼: {scale}, ë“œë¡  ì›ë³¸ í¬ê¸°: {drone_orig_w}x{drone_orig_h}")
        drone_resized = cv2.resize(drone, (0, 0), fx=scale, fy=scale)
        
        # ë“œë¡  íšŒì „ ì ìš© ì œì™¸
        drone_h, drone_w = drone_resized.shape[:2]
        print(f"í¬ê¸° ì¡°ì • í›„ ë“œë¡  í¬ê¸°: {drone_w}x{drone_h}, ë°°ê²½ í¬ê¸°: {bg_w}x{bg_h}")
        
        # íšŒì „ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        drone_rotated = drone_resized
        
        # ë“œë¡  ìœ„ì¹˜ ì„ íƒ (í™”ë©´ ì¤‘ì•™ì— ê°€ê¹ê²Œ)
        # ë°°ê²½ ì´ë¯¸ì§€ì—ì„œ ë“œë¡ ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ ë²”ìœ„ ê³„ì‚°
        max_x = max(1, bg_w - drone_w)
        max_y = max(1, bg_h - drone_h)
        
        # ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ì¤‘ì•™ ê·¼ì²˜ì— ë°°ì¹˜
        x_left = max(0, min(bg_w//4, max_x//4))
        x_right = max(x_left + 1, min(bg_w*3//4, max_x))
        y_top = max(0, min(bg_h//4, max_y//4))
        y_bottom = max(y_top + 1, min(bg_h*3//4, max_y))
        
        x_pos = random.randint(x_left, x_right)
        y_pos = random.randint(y_top, y_bottom)
        # y_pos = (0)
        
        print(f"ë“œë¡  ìœ„ì¹˜: ({x_pos}, {(y_pos)})")
        
        # í•©ì„±í•  ë°°ê²½ ì˜ì—­ ì¤€ë¹„
        roi = background[y_pos:y_pos+drone_h, x_pos:x_pos+drone_w]
        
        # ì•ŒíŒŒ ë¸”ë Œë”©ìœ¼ë¡œ ì´ë¯¸ì§€ í•©ì„±
        try:
            if drone_rotated.shape[2] == 4:  # ì•ŒíŒŒ ì±„ë„ ì¡´ì¬
                # ì•ŒíŒŒ ë§ˆìŠ¤í¬ ì¶”ì¶œ
                alpha_mask = drone_rotated[:, :, 3] / 255.0
                alpha_mask_3d = np.stack([alpha_mask] * 3, axis=2)
                
                # ì•ŒíŒŒ ë¸”ë Œë”©
                foreground = drone_rotated[:, :, :3]
                blended_img = foreground * alpha_mask_3d + roi * (1 - alpha_mask_3d)
                
                # í•©ì„± ê²°ê³¼ë¥¼ ë°°ê²½ì— ì ìš©
                background[y_pos:y_pos+drone_h, x_pos:x_pos+drone_w] = blended_img
            else:
                # ì•ŒíŒŒ ì±„ë„ì´ ì—†ëŠ” ê²½ìš° ê·¸ëƒ¥ ë³µì‚¬
                background[y_pos:y_pos+drone_h, x_pos:x_pos+drone_w] = drone_rotated[:, :, :3]
        except Exception as e:
            print(f"ì´ë¯¸ì§€ í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"ë“œë¡  í¬ê¸°: {drone_rotated.shape}, ROI í¬ê¸°: {roi.shape}")
            continue
        
        # YOLO í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ë¼ë²¨ ìƒì„±
        drone_center_x = (x_pos + drone_w/2) / bg_w
        drone_center_y = (y_pos + drone_h/2) / bg_h
        drone_width = drone_w / bg_w
        drone_height = drone_h / bg_h
        
        # ë“œë¡  íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ì €ì¥ íŒŒì¼ëª… ìƒì„±
        output_filename = f"{drone_base_name}_{i:04d}.png"
        label_filename = f"{drone_base_name}_{i:04d}.txt"
        
        # ì´ë¯¸ì§€ ì €ì¥
        output_path = os.path.join(output_dir, output_filename)
        cv2.imwrite(output_path, background)
        
        # ë¼ë²¨ ì €ì¥ (YOLO í˜•ì‹) - ë“œë¡  ì‹œê·¸ë„ì— ë”°ë¼ í´ë˜ìŠ¤ ID ì‚¬ìš©
        label_path = os.path.join(output_dir, label_filename)
        with open(label_path, 'w') as f:
            f.write(f"{class_id} {drone_center_x} {drone_center_y} {drone_width} {drone_height}\n")
    
    print(f"{num_images}ê°œì˜ í•©ì„± ì´ë¯¸ì§€ê°€ {output_dir}ì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

#############################
# ê°ì²´ í¬í•¨ ì—¬ë¶€ íŒë‹¨ ì •ë°€í™” 
#############################
def batch_slice_yolo_polygon(input_img_dir, input_label_dir, output_dir, tile_size=1024, overlap=0.1):
    out_img_path = os.path.join(output_dir, 'images')
    out_label_path = os.path.join(output_dir, 'labels')
    os.makedirs(out_img_path, exist_ok=True)
    os.makedirs(out_label_path, exist_ok=True)

    img_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
    img_files = []
    for ext in img_extensions:
        img_files.extend(glob.glob(os.path.join(input_img_dir, ext)))

    print(f"ğŸš€ ì´ {len(img_files)}ê°œ íŒŒì¼ ìŠ¬ë¼ì´ì‹± ì‹œì‘ (Polygon ì§€ì› ëª¨ë“œ)")

    for img_path in tqdm(img_files):
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        label_path = os.path.join(input_label_dir, f"{img_name}.txt")

        if not os.path.exists(label_path): continue

        image = cv2.imread(img_path)
        if image is None: continue
        h, w, _ = image.shape
        
        with open(label_path, 'r') as f:
            lines = f.readlines()

        step = int(tile_size * (1 - overlap))

        for y in range(0, h, step):
            for x in range(0, w, step):
                # íƒ€ì¼ ê²½ê³„ ê³„ì‚°
                x_end = min(x + tile_size, w)
                y_end = min(y + tile_size, h)
                x_start = max(0, x_end - tile_size)
                y_start = max(0, y_end - tile_size)

                tile_labels = []

                for line in lines:
                    parts = line.strip().split()
                    if len(parts) < 5: continue
                    
                    class_id = parts[0]
                    coords = list(map(float, parts[1:]))
                    
                    # í”½ì…€ ì¢Œí‘œ ë³µì›
                    px_pts = []
                    if len(parts) == 5: # Bbox (xc, yc, w, h)
                        abs_xc, abs_yc = coords[0] * w, coords[1] * h
                        abs_w, abs_h = coords[2] * w, coords[3] * h
                        px_pts = [
                            (abs_xc - abs_w/2, abs_yc - abs_h/2),
                            (abs_xc + abs_w/2, abs_yc - abs_h/2),
                            (abs_xc + abs_w/2, abs_yc + abs_h/2),
                            (abs_xc - abs_w/2, abs_yc + abs_h/2)
                        ]
                    else: # Polygon (x1, y1, x2, y2, ...)
                        for i in range(0, len(coords), 2):
                            px_pts.append((coords[i] * w, coords[i+1] * h))
                    
                    # --- [ìˆ˜ì • ë° ê°•í™”ëœ ë¡œì§] ---
                    # 1. ê°ì²´ì˜ ì ë“¤ ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤ì œ íƒ€ì¼ ì˜ì—­ ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                    is_inside = False
                    for pt_x, pt_y in px_pts:
                        if x_start <= pt_x <= x_end and y_start <= pt_y <= y_end:
                            is_inside = True
                            break
                    
                    # 2. ê°ì²´ê°€ íƒ€ì¼ì— í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                    if is_inside:
                        new_poly = []
                        for pt_x, pt_y in px_pts:
                            # íƒ€ì¼ ê²½ê³„ë¡œ ê³ ì •
                            cx = max(x_start, min(pt_x, x_end))
                            cy = max(y_start, min(pt_y, y_end))
                            # ìƒëŒ€ ì¢Œí‘œ ë³€í™˜ ë° ì •ê·œí™”
                            nx = (cx - x_start) / tile_size
                            ny = (cy - y_start) / tile_size
                            new_poly.append(f"{nx:.6f} {ny:.6f}")

                        # ìœ íš¨í•œ í´ë¦¬ê³¤ì¸ì§€ í™•ì¸ (ì  6ê°œ ì´ìƒ)
                        if len(set(new_poly)) >= 6: # 3:
                            tile_labels.append(f"{class_id} {' '.join(new_poly)}")

                # --- [í•µì‹¬] ê°ì²´ê°€ ë°œê²¬ëœ íƒ€ì¼ë§Œ ì €ì¥ ---
                if tile_labels:
                    tile_img = image[y_start:y_end, x_start:x_end]
                    save_name = f"{img_name}_{x_start}_{y_start}"
                    
                    cv2.imwrite(os.path.join(out_img_path, f"{save_name}.jpg"), tile_img)
                    with open(os.path.join(out_label_path, f"{save_name}.txt"), 'w') as f_out:
                        f_out.write("\n".join(tile_labels))
#############################

def batch_slice_yolo_polygon_integrated(input_img_dir, input_label_dir, output_dir, tile_size=1024, overlap=0.2):
    """
    ì‚° ëª¨ì–‘ í´ë¦¬ê³¤ ë¼ë²¨ì„ ì§€ì›í•˜ëŠ” ì •ë°€ ìŠ¬ë¼ì´ì‹± í•¨ìˆ˜
    """
    out_img_path = os.path.join(output_dir, 'images')
    out_label_path = os.path.join(output_dir, 'labels')
    os.makedirs(out_img_path, exist_ok=True)
    os.makedirs(out_label_path, exist_ok=True)
                                                          
    img_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
        img_files.extend(glob.glob(os.path.join(input_img_dir, ext)))

    print(f"ğŸš€ ì‚° ëª¨ì–‘ í´ë¦¬ê³¤ í†µí•© ìŠ¬ë¼ì´ì‹± ì‹œì‘: {len(img_files)}ê°œ íŒŒì¼")

    for img_path in tqdm(img_files):
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        label_path = os.path.join(input_label_dir, f"{img_name}.txt")

        if not os.path.exists(label_path): continue

        image = cv2.imread(img_path)
        if image is None: continue
        h, w, _ = image.shape
        
        with open(label_path, 'r') as f:
            lines = f.readlines()

        step = int(tile_size * (1 - overlap))

        for y in range(0, h, step):
            for x in range(0, w, step):
                # íƒ€ì¼ ë²”ìœ„ ê²°ì • (ì´ë¯¸ì§€ ëë‹¨ ì²˜ë¦¬)
                x_end = min(x + tile_size, w)
                y_end = min(y + tile_size, h)
                x_start = max(0, x_end - tile_size)
                y_start = max(0, y_end - tile_size)

                tile_labels = []

                for line in lines:
                    parts = line.strip().split()
                    if not parts: continue
                    
                    class_id = parts[0]
                    coords = list(map(float, parts[1:]))

                    if len(coords) == 4: # ë°•ìŠ¤ í˜•ì‹ (xc, yc, w, h)ì¸ ê²½ìš°
                        xc, yc, w_val, h_val = coords
                        # 4ê°œì˜ í´ë¦¬ê³¤ ì ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ px_pts ìƒì„±
                        px_pts = np.array([
                            [xc - w_val/2, yc - h_val/2], [xc + w_val/2, yc - h_val/2],
                            [xc + w_val/2, yc + h_val/2], [xc - w_val/2, yc + h_val/2]
                        ]) * [w, h]
                    else: # í´ë¦¬ê³¤ í˜•ì‹ì¸ ê²½ìš°
                        px_pts = np.array(coords).reshape(-1, 2) * [w, h]

                    # 1. ê°ì²´ì˜ ì ë“¤ì´ í˜„ì¬ íƒ€ì¼ ì•ˆì— í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ ì²´í¬
                    # ì‚° ëª¨ì–‘ì˜ ê²½ìš° Peak ì¤‘ í•˜ë‚˜ë¼ë„ íƒ€ì¼ì— ë“¤ì–´ì™€ì•¼ ìœ íš¨í•¨
                    inside_mask = (px_pts[:, 0] >= x_start) & (px_pts[:, 0] <= x_end) & \
                                  (px_pts[:, 1] >= y_start) & (px_pts[:, 1] <= y_end)
                    
                    # ê²½ê³„ì— ê±¸ë¦´ ê²½ìš° í´ë¦¬í•‘
                    if np.any(inside_mask):
                        # 2. íƒ€ì¼ ê²½ê³„ë¡œ í´ë¦¬í•‘ (Clamping)
                        # ì‚° ëª¨ì–‘ì˜ êµ´ê³¡ì´ íƒ€ì¼ ë°–ìœ¼ë¡œ ë‚˜ê°€ë„ ê²½ê³„ì„ ì— ë¶™ì—¬ì„œ í˜•íƒœ ìœ ì§€                                                                      
                        new_poly = []
                        for pt_x, pt_y in px_pts:  
                            cx = np.clip(pt_x, x_start, x_end)
                            cy = np.clip(pt_y, y_start, y_end)
                            
                            # 3. íƒ€ì¼ ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜ ë° ì •ê·œí™”
                            nx = (cx - x_start) / tile_size
                            ny = (cy - y_start) / tile_size
                            new_poly.append(f"{nx:.6f} {ny:.6f}")

                        # 4. ìœ íš¨ì„± ê²€ì‚¬ (ì  ì¤‘ë³µ ì œê±° í›„ ë©´ì ì´ í˜•ì„±ë˜ëŠ”ì§€ í™•ì¸)
                        if len(set(new_poly)) >= 6: # 3:
                            tile_labels.append(f"{class_id} {' '.join(new_poly)}")

                # 5. ë¼ë²¨ì´ ì¡´ì¬í•˜ëŠ” íƒ€ì¼ë§Œ íŒŒì¼ë¡œ ì €ì¥
                if tile_labels:
                    tile_img = image[y_start:y_end, x_start:x_end]
                    save_name = f"{img_name}_tile_{x_start}_{y_start}"
                    
                    cv2.imwrite(os.path.join(out_img_path, f"{save_name}.png"), tile_img)
                    with open(os.path.join(out_label_path, f"{save_name}.txt"), 'w') as f_out:
                        f_out.write("\n".join(tile_labels))

    print(f"âœ… ìŠ¬ë¼ì´ì‹± ì™„ë£Œ. ì €ì¥ê²½ë¡œ: {output_dir}")

def batch_slice_yolo_polygon_complete_only(input_img_dir, input_label_dir, output_dir, tile_size=1024, overlap=0.3):
    """
    ê²½ê³„ì— ê±¸ë¦° ê°ì²´ëŠ” ë¬´ì‹œí•˜ê³ , íƒ€ì¼ ë‚´ë¶€ì— ì™„ì „íˆ í¬í•¨ëœ ê°ì²´ë§Œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    out_img_path = os.path.join(output_dir, 'images')
    out_label_path = os.path.join(output_dir, 'labels')
    os.makedirs(out_img_path, exist_ok=True)
    os.makedirs(out_label_path, exist_ok=True)

    img_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
        img_files.extend(glob.glob(os.path.join(input_img_dir, ext)))

    print(f"ğŸš€ ì™„ì „ í¬í•¨ ê°ì²´ ì „ìš© ìŠ¬ë¼ì´ì‹± ì‹œì‘: {len(img_files)}ê°œ íŒŒì¼")

    for img_path in tqdm(img_files):
        img_name = os.path.splitext(os.path.basename(img_path))[0]
        label_path = os.path.join(input_label_dir, f"{img_name}.txt")
        if not os.path.exists(label_path): continue

        image = cv2.imread(img_path)
        if image is None: continue
        h, w, _ = image.shape
        
        with open(label_path, 'r') as f:
            lines = f.readlines()

        # ê²½ê³„ ë¬´ì‹œ ëª¨ë“œì—ì„œëŠ” Overlapì„ 0.3 ì •ë„ë¡œ ë†’ê²Œ ì¡ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        step = int(tile_size * (1 - overlap))

        for y in range(0, h, step):
            for x in range(0, w, step):
                x_end = min(x + tile_size, w)
                y_end = min(y + tile_size, h)
                x_start = max(0, x_end - tile_size)
                y_start = max(0, y_end - tile_size)

                tile_labels = []

                for line in lines:
                    parts = line.strip().split()
                    if not parts: continue
                    
                    class_id = parts[0]
                    coords = list(map(float, parts[1:]))

                    # 1. ì¢Œí‘œ ë³µì› ë° ì  ë°°ì—´ ìƒì„±
                    if len(coords) == 4: # Bbox
                        xc, yc, w_val, h_val = coords
                        px_pts = np.array([
                            [xc - w_val/2, yc - h_val/2], [xc + w_val/2, yc - h_val/2],
                            [xc + w_val/2, yc + h_val/2], [xc - w_val/2, yc + h_val/2]
                        ]) * [w, h]
                    else: # Polygon
                        px_pts = np.array(coords).reshape(-1, 2) * [w, h]

                    # 2. í•µì‹¬ ë¡œì§: ëª¨ë“  ì ì´ íƒ€ì¼ ì˜ì—­ ë‚´ë¶€ì— ìˆëŠ”ì§€ ì²´í¬ (np.all)
                    inside_mask = (px_pts[:, 0] >= x_start) & (px_pts[:, 0] <= x_end) & \
                                  (px_pts[:, 1] >= y_start) & (px_pts[:, 1] <= y_end)
                    
                    if np.all(inside_mask): # í•˜ë‚˜ë¼ë„ ë°–ì— ìˆìœ¼ë©´ False
                        new_poly = []
                        for pt_x, pt_y in px_pts:
                            # ëª¨ë“  ì ì´ ë‚´ë¶€ì— ìˆìœ¼ë¯€ë¡œ clipì€ ì‚¬ì‹¤ìƒ ì˜ˆì™¸ ë°©ì§€ìš©
                            nx = (pt_x - x_start) / tile_size
                            ny = (pt_y - y_start) / tile_size
                            new_poly.append(f"{nx:.6f} {ny:.6f}")

                        if len(new_poly) >= 3:
                            tile_labels.append(f"{class_id} {' '.join(new_poly)}")

                # 3. ì˜¨ì „í•œ ê°ì²´ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” íƒ€ì¼ë§Œ ì €ì¥
                if tile_labels:
                    tile_img = image[y_start:y_end, x_start:x_end]
                    save_name = f"{img_name}_tile_{x_start}_{y_start}"
                    cv2.imwrite(os.path.join(out_img_path, f"{save_name}.png"), tile_img)
                    with open(os.path.join(out_label_path, f"{save_name}.txt"), 'w') as f_out:
                        f_out.write("\n".join(tile_labels))

def create_tile_gallery(sliced_img_dir, sliced_label_dir, output_file, grid_size=(4, 4), thumb_size=(400, 400)):
    """
    ìŠ¬ë¼ì´ì‹±ëœ íƒ€ì¼ë“¤ê³¼ ë¼ë²¨ì„ ì‹œê°í™”í•˜ì—¬ í•˜ë‚˜ì˜ í° ê°¤ëŸ¬ë¦¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
    """
    img_list = glob.glob(os.path.join(sliced_img_dir, "*.png")) + \
               glob.glob(os.path.join(sliced_img_dir, "*.jpg"))
    
    if not img_list:
        print("âŒ ì‹œê°í™”í•  íƒ€ì¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìµœì‹  ìƒì„±ëœ íŒŒì¼ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê±°ë‚˜ ëœë¤ ì„ íƒ
    np.random.shuffle(img_list)
    selected_imgs = img_list[:grid_size[0] * grid_size[1]]

    gallery_rows = []
    for i in range(grid_size[0]):
        row_imgs = []
        for j in range(grid_size[1]):
            idx = i * grid_size[1] + j
            if idx >= len(selected_imgs):
                # ë¹ˆ ì¹¸ì€ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ë¡œ ì±„ì›€
                row_imgs.append(np.zeros((thumb_size[1], thumb_size[0], 3), dtype=np.uint8))
                continue

            # ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
            img_path = selected_imgs[idx]
            img = cv2.imread(img_path)
            h, w = img.shape[:2]
            
            # í•´ë‹¹ ë¼ë²¨ ì°¾ê¸°
            label_path = os.path.join(sliced_label_dir, os.path.splitext(os.path.basename(img_path))[0] + ".txt")
            
            if os.path.exists(label_path):
                with open(label_path, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if not parts: continue
                        
                        # í´ë¦¬ê³¤ ì¢Œí‘œ ë³µì› (ì •ê·œí™” -> í”½ì…€)
                        coords = np.array(list(map(float, parts[1:]))).reshape(-1, 2)
                        px_pts = (coords * [w, h]).astype(np.int32)
                        
                        # íƒ€ì¼ì— ë¼ë²¨ ê·¸ë¦¬ê¸° (ë…¸ë€ìƒ‰ ì„  + ë¹¨ê°„ìƒ‰ ì )
                        cv2.polylines(img, [px_pts.reshape((-1, 1, 2))], True, (0, 255, 255), 2)
                        for pt in px_pts:
                            cv2.circle(img, tuple(pt), 4, (0, 0, 255), -1)

            # ì¸ë„¤ì¼ í¬ê¸°ë¡œ ë³€í™˜
            thumb = cv2.resize(img, thumb_size)
            # íƒ€ì¼ íŒŒì¼ëª… ê¸°ì… (ì˜µì…˜)
            cv2.putText(thumb, os.path.basename(img_path)[:15], (10, 25), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            row_imgs.append(thumb)

        gallery_rows.append(np.hstack(row_imgs))

    final_gallery = np.vstack(gallery_rows)
    cv2.imwrite(output_file, final_gallery)
    print(f"âœ… ê°¤ëŸ¬ë¦¬ ìƒì„± ì™„ë£Œ: {output_file}")

def main():
    parser = argparse.ArgumentParser(description="ê°ì²´ ì¸ì‹ ë°ì´í„°ì…‹ ì¤€ë¹„ ë„êµ¬")
    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹ì–´')
    
    # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    create_parser = subparsers.add_parser('create', help='ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±')
    create_parser.add_argument('--dir', type=str, required=True, help='ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    split_parser = subparsers.add_parser('split', help='ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• ')
    split_parser.add_argument('--images', type=str, required=True, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_parser.add_argument('--labels', type=str, required=True, help='ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_parser.add_argument('--masks', type=str, help='ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì„ íƒì )')
    split_parser.add_argument('--output', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_parser.add_argument('--train', type=float, default=0.7, help='í•™ìŠµ ë°ì´í„° ë¹„ìœ¨')
    split_parser.add_argument('--val', type=float, default=0.2, help='ê²€ì¦ ë°ì´í„° ë¹„ìœ¨')
    split_parser.add_argument('--test', type=float, default=0.1, help='í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨')
    split_parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')

    # ìŠ¬ë¼ì´ì‹± ë°ì´í„°ì…‹ ë¶„í• 
    split_sliced_parser = subparsers.add_parser('split_sliced', help='ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• ')
    split_sliced_parser.add_argument('--images', type=str, required=True, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_sliced_parser.add_argument('--labels', type=str, required=True, help='ë¼ë²¨ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_sliced_parser.add_argument('--output', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    split_sliced_parser.add_argument('--train', type=float, default=0.7, help='í•™ìŠµ ë°ì´í„° ë¹„ìœ¨')
    split_sliced_parser.add_argument('--val', type=float, default=0.2, help='ê²€ì¦ ë°ì´í„° ë¹„ìœ¨')
    split_sliced_parser.add_argument('--test', type=float, default=0.1, help='í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨')
    split_sliced_parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    
    # ë§ˆìŠ¤í¬ ìƒì„±
    mask_parser = subparsers.add_parser('mask', help='ë°”ìš´ë”© ë°•ìŠ¤ë¡œë¶€í„° ë§ˆìŠ¤í¬ ìƒì„±')
    mask_parser.add_argument('--dir', type=str, required=True, help='ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ (ì´ë¯¸ì§€ì™€ ë¼ë²¨ í¬í•¨)')
    mask_parser.add_argument('--output', type=str, help='ë§ˆìŠ¤í¬ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì„ íƒì )')
    mask_parser.add_argument('--dilation', type=int, default=5, help='ë°”ìš´ë”© ë°•ìŠ¤ íŒ½ì°½ í¬ê¸° (í”½ì…€)')
    
    # ë°ì´í„° ì¦ê°•
    augment_parser = subparsers.add_parser('augment', help='ë°ì´í„°ì…‹ ì¦ê°•')
    augment_parser.add_argument('--dir', type=str, required=True, help='ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬')
    augment_parser.add_argument('--num', type=int, default=5, help='ê° ì´ë¯¸ì§€ë‹¹ ìƒì„±í•  ì¦ê°• ì´ë¯¸ì§€ ìˆ˜')
    augment_parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')
    
    # ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°
    preview_parser = subparsers.add_parser('preview', help='ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°')
    preview_parser.add_argument('--dir', type=str, required=True, help='ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬')
    preview_parser.add_argument('--num', type=int, default=5, help='ë¯¸ë¦¬ë³¼ ìƒ˜í”Œ ìˆ˜')
    preview_parser.add_argument('--seed', type=int, default=42, help='ëœë¤ ì‹œë“œ')

    # íƒ€ì¼ ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°
    preview_parser = subparsers.add_parser('view_tile', help='íƒ€ì¼ ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°')
    preview_parser.add_argument('--image_dir', type=str, required=True, help='íƒ€ì¼ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬')
    preview_parser.add_argument('--label_dir', type=str, required=True, help='íƒ€ì¼ ë¼ë²¨ ë””ë ‰í† ë¦¬')
    preview_parser.add_argument('--out_file', type=str, required=True, help='ê°¤ëŸ¬ë¦¬ ì¶œë ¥ ì´ë¯¸ì§€')
    preview_parser.add_argument('--grid', type=int, nargs=2, default=[4, 4], help='ê·¸ë¦¬ë“œ ê°€ë¡œ ì„¸ë¡œ ì‚¬ì´ì¦ˆ (ì˜ˆ: --grid 4 4)')
    
    # ë°ì´í„°ì…‹ ë§Œë“¤ê¸°
    synthetic_parser = subparsers.add_parser('synthetic', help='ë°ì´í„°ì…‹ ë§Œë“¤ê¸°')
    synthetic_parser.add_argument('--drone', type=str, required=True, help='ë“œë¡  ì´ë¯¸ì§€')
    synthetic_parser.add_argument('--back', type=str, required=True, help='ë°±ê·¸ë¼ìš´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    synthetic_parser.add_argument('--output', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    synthetic_parser.add_argument('--num', type=int, default=5, help='ì´ë¯¸ì§€ ìƒì„± ê°œìˆ˜')
    
    # ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ìŠ¤ì¼€ì¼ëŸ¿ ë§ˆìŠ¤í¬ ì ìš©)
    synthetic_skeletal_parser = subparsers.add_parser('synthetic_skeletal', help='ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ìŠ¤ì¼€ì¼ëŸ¿ ë§ˆìŠ¤í¬ ì ìš©)')
    synthetic_skeletal_parser.add_argument('--drone', type=str, required=True, help='ë“œë¡  ì´ë¯¸ì§€')
    synthetic_skeletal_parser.add_argument('--back_dir', type=str, required=True, help='ë°±ê·¸ë¼ìš´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    synthetic_skeletal_parser.add_argument('--output_dir', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    synthetic_skeletal_parser.add_argument('--num', type=int, default=5, help='ì´ë¯¸ì§€ ìƒì„± ê°œìˆ˜')
    synthetic_skeletal_parser.add_argument('--mask_type', type=str, default='polygon', help='ë§ˆìŠ¤í¬ íƒ€ì… (line, polygon)')

    # ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (mountain ëª¨ì–‘ ìŠ¤ì¼€ì¼ëŸ¿ ë§ˆìŠ¤í¬ ì ìš©)
    synthetic_skeletal_parser = subparsers.add_parser('synthetic_mountain', help='ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ì‹ í˜¸ íŒ¨í„´ì´ ìŒë´‰ ëª¨ì–‘ì¼ ê²½ìš° ì ìš©)')
    synthetic_skeletal_parser.add_argument('--drone', type=str, required=True, help='ë“œë¡  ì´ë¯¸ì§€')
    synthetic_skeletal_parser.add_argument('--back_dir', type=str, required=True, help='ë°±ê·¸ë¼ìš´ë“œ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    synthetic_skeletal_parser.add_argument('--output_dir', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    synthetic_skeletal_parser.add_argument('--num', type=int, default=5, help='ì´ë¯¸ì§€ ìƒì„± ê°œìˆ˜')
    synthetic_skeletal_parser.add_argument('--mask_type', type=str, default='polygon', help='ë§ˆìŠ¤í¬ íƒ€ì… (line, polygon)')

    # ë°ì´í„°ì…‹ ìŠ¬ë¼ì´ìŠ¤
    slicing_image_parser = subparsers.add_parser('slice_image', help='ë°ì´í„°ì…‹ ìŠ¬ë¼ì´ìŠ¤ ë§Œë“¤ê¸°(í°ì´ë¯¸ì§€ë¥¼ ì‘ê²Œ ìª¼ê°œê¸°)')
    slicing_image_parser.add_argument('--img_dir', type=str, required=True, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬')
    slicing_image_parser.add_argument('--label_dir', type=str, required=True, help='ë¼ë²¨ë²¨ ë””ë ‰í† ë¦¬')
    slicing_image_parser.add_argument('--output_dir', type=str, required=True, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    slicing_image_parser.add_argument('--size', type=int, default=128, help='ìŠ¬ë¼ì´ìŠ¤ ì´ë¯¸ì§€ í¬ê¸°')
    slicing_image_parser.add_argument('--overlap', type=float, default=0.1, help='ì˜¤ë²„ë© í¬ê¸°ê¸°')
    
    # íŒŒì¼ ì‚­ì œ
    delete_parser = subparsers.add_parser('delete', help='íŠ¹ì • ì ‘ë¯¸ì‚¬ë¥¼ í¬í•¨í•˜ëŠ” íŒŒì¼ ì‚­ì œ')
    delete_parser.add_argument('--dir', type=str, required=True, help='ëŒ€ìƒ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    delete_parser.add_argument('--suffix', type=str, required=True, help='ì‚­ì œí•  íŒŒì¼ì˜ ì ‘ë¯¸ì‚¬')
    
    args = parser.parse_args()
    
    if args.command == 'create':
        create_directory_structure(args.dir)
    elif args.command == 'split':
        split_dataset(args.images, args.labels, args.masks, args.output, 
                     args.train, args.val, args.test, args.seed)
    elif args.command == 'split_sliced':
        split_sliced_dataset(args.images, args.labels, args.output, 
                     args.train, args.val, args.test, args.seed)
    elif args.command == 'mask':
        create_masks_for_dataset(args.dir, args.output, args.dilation)
    elif args.command == 'augment':
        augment_dataset(args.dir, args.num, args.seed)
    elif args.command == 'preview':
        preview_dataset(args.dir, args.num, args.seed)
    elif args.command == 'view_tile':
        create_tile_gallery(args.image_dir, args.label_dir, args.out_file)
    elif args.command == 'synthetic':
        create_synthetic_drone_images(args.drone, args.back, args.output, args.num)
    elif args.command == 'synthetic_skeletal':
        synthesize_advanced(args.drone, args.back_dir, args.output_dir, args.num, args.mask_type) # ì¼ë°˜ ì‚¬ê°í˜• í˜•íƒœì— ì ìš©.
    elif args.command == 'synthetic_mountain':
        synthesize_advanced_mountain_shape(args.drone, args.back_dir, args.output_dir, args.num, args.mask_type) # ë¾°ì¡±í•œ ì‚°ëª¨ì–‘ì˜ ê²½ìš° ì ìš©.
    elif args.command == 'slice_image':
        # batch_slice_yolo_polygon(args.img_dir, args.label_dir, args.output_dir, args.size, args.overlap) # Boxì™€ polygon ë³„ë„ë¡œ ë¶„ë¦¬
        # batch_slice_yolo_polygon_integrated(args.img_dir, args.label_dir, args.output_dir, args.size, args.overlap) # ëª¨ë“  í˜•ì‹ polygonìœ¼ë¡œ í†µì¼
        batch_slice_yolo_polygon_complete_only(args.img_dir, args.label_dir, args.output_dir, args.size, args.overlap) # ëª¨ë“  ê°ì²´ê°€ íƒ€ì¼ì•ˆì— ìˆëŠ” ê²½ìš°ë§Œ ì €ì¥
    elif args.command == 'delete':
        delete_files_with_suffix(args.dir, args.suffix)
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 

########################################################
## command example
########################################################
drone_path = './datasets/drone_data/signal/mini2_sig1_1.png'    # ì‚¬ìš©í•  ì‹œê·¸ë„ ì´ë¯¸ì§€ íŒŒì¼ 
background_dir = './datasets/drone_data/background'     # ë°°ê²½ ì´ë¯¸ì§€ë“¤ì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œ
synthetic_output_dir = './datasets/synthetic' # í•©ì„± ì´ë¯¸ì§€ ì €ì¥ë  ê²½ë¡œ
img_dir = './datasets/synthetic/images'
label_dir = './datasets/synthetic/labels'
sliced_out_dir = './datasets/synthetic/sliced_data'
sliced_img_dir = './datasets/synthetic/sliced_data/images'
sliced_label_dir = './datasets/synthetic/sliced_data/labels'
final_output_dir = './datasets' # ìµœì¢… ë¶„í•  ë°ì´í„°ì…‹ ì €ì¥ë  ê²½ë¡œ

##############################################
# # ìŠ¬ë¼ì´ìŠ¤ëœ ì´ë¯¸ì§€+ë¼ë²¨ view
##############################################
# create_tile_gallery(sliced_img_dir, sliced_label_dir, './datasets/synthetic/sliced_data/tile_view.png', grid_size=(4, 4), thumb_size=(400, 400))

##############################################
# # ë“œë¡  ì´ë¯¸ì§€ í•©ì„± (ë°•ìŠ¤ ë§ˆìŠ¤í¬ ì ìš©)
##############################################
# # python prepare_data.py synthetic --drone ./datasets/drone_data/signal/autelevo_01_sig_2.png --back ./datasets/drone_data/background --output ./datasets/synthetic --num 100
# create_synthetic_drone_images(drone_path, background_dir, synthetic_output_dir, num_images=50)

##############################################
# # ë“œë¡  ì´ë¯¸ì§€ í•©ì„± (ìŠ¤ì¼€ì¼ëŸ¿ ë§ˆìŠ¤í¬ ì ìš©) - ì‹ í˜¸ íŒ¨í„´ì´ ë‹¨ìˆœ ì‚¬ê°í˜• ëª¨ì–‘ì¼ ê²½ìš° ì ìš©
##############################################
# # python prepare_data.py synthetic_skeletal --drone ./datasets/drone_data/signal/signal_4.png --back_dir ./datasets/drone_data/background --output_dir ./datasets/synthetic --num 5 --mask_type line
# synthesize_advanced(drone_path, background_dir, synthetic_output_dir, num_gen=50, mask_type='polygon') # mask_type='line')

##############################################
# # ë“œë¡  ì´ë¯¸ì§€ í•©ì„± (ì‚°ëª¨ì–‘ ìŠ¤ì¼€ì¼ëŸ¿ ë§ˆìŠ¤í¬ ì ìš©) - ì‹ í˜¸ íŒ¨í„´ì´ ìŒë´‰ ëª¨ì–‘ì¼ ê²½ìš° ì ìš©
##############################################
# # python prepare_data.py synthetic_mountain --drone ./datasets/drone_data/signal/signal_4.png --back_dir ./datasets/drone_data/background --output_dir ./datasets/synthetic --num 5 --mask_type line
# synthesize_advanced_mountain_shape(drone_path, background_dir, synthetic_output_dir, num_gen=50, mask_type='polygon')

##############################################
# # í•©ì„± ì´ë¯¸ì§€ ìŠ¬ë¼ì´ì‹±
##############################################
# python prepare_data.py slice_image --img_dir ./datasets/drone_data/signal --label_dir ./datasets/drone_data/background --output_dir ./datasets/synthetic --size 2560 --overlap 0.3
# batch_slice_yolo_polygon(img_dir, label_dir, sliced_out_dir, tile_size=2560, overlap=0.4) # Boxì™€ polygon ë³„ë„ë¡œ ë¶„ë¦¬
# batch_slice_yolo_polygon_integrated(img_dir, label_dir, sliced_out_dir, tile_size=2560, overlap=0.4) # ëª¨ë“  í˜•ì‹ polygonìœ¼ë¡œ í†µì¼
# batch_slice_yolo_polygon_complete_only(img_dir, label_dir, sliced_out_dir, tile_size=2560, overlap=0.4) # ëª¨ë“  ê°ì²´ê°€ íƒ€ì¼ì•ˆì— ìˆëŠ” ê²½ìš°ë§Œ ì €ì¥

##############################################
# # ì›ë³¸ ì´ë¯¸ì§€ ë¶„í•  (train, val, test)  
# ############################################## 
# # python prepare_data.py split --images ./datasets/synthetic --labels ./datasets/synthetic --output ./datasets --train 0.7 --val 0.2 --test 0.1
# split_dataset(img_dir, label_dir, None, final_output_dir, train_ratio=0.8, val_ratio=0.2, test_ratio=0.0)

##############################################
# # ìŠ¬ë¼ì´ì‹± ì´ë¯¸ì§€ ë¬¶ìŒ ë¶„í•  (train, val, test)
##############################################
# # python prepare_data.py split_sliced --images ./datasets/synthetic/images --labels ./datasets/synthetic/labels --output ./datasets --train 0.7 --val 0.2 --test 0.1
# split_sliced_dataset(sliced_img_dir, sliced_label_dir, final_output_dir, train_ratio=0.8, val_ratio=0.2, test_ratio=0.0)